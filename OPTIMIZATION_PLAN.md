# Анализ проблемы размера ответа

## Проблема
Ответ от `get_orders` содержит избыточное количество данных:
1.  **Полные данные клиента** внутри каждого заказа (включая все его сегменты, теги, кастомные поля).
2.  **Сегменты клиента** занимают огромный объем (сотни строк JSON на один заказ).
3.  **Лишние технические поля** (site, orderMethod, delivery, etc.), которые часто не нужны для простых вопросов типа "сколько заказов".

Это приводит к тому, что:
*   Контекстное окно LLM быстро забивается.
*   Модели "теряются" в шуме и галлюцинируют.
*   Ответы приходят медленно.
*   Растет стоимость токенов.

## Решение: Фильтрация полей (Field Selection)

Мы добавим новый параметр `fields` в инструменты `get_orders` и `get_customers`.

### Как это будет работать:
1.  По умолчанию (если `fields` не передан) возвращаем **упрощенную** версию объекта (только ID, номер, статус, сумма, дата).
2.  Если нужны детали, AI должен явно запросить их (например, `fields: ["items", "customer"]`).
3.  Мы реализуем функцию `pickFields`, которая будет рекурсивно оставлять только нужные ключи в ответе перед отправкой в LLM.

### Пример оптимизации
**Было (1 заказ ~ 5KB):**
```json
{
  "id": 123,
  "customer": { ... 50 полей ... },
  "items": [ ... 20 полей ... ],
  "delivery": { ... },
  ...
}
```

**Станет (по умолчанию ~ 200 байт):**
```json
{
  "id": 123,
  "number": "100500",
  "status": "complete",
  "sum": 5000,
  "createdAt": "2025-12-01 12:00:00"
}
```

Это сократит объем контекста в 20-50 раз!
